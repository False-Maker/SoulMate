# 对话×本地记忆联动改造（一次到位设计文档）

## 1. 背景与问题
当前项目已经有“本地记忆库（ObjectBox + 向量检索）”与“对话调用 LLM”的基础能力，但存在两个核心不足：
1) 只有“长期记忆 RAG”联动，没有“会话聊天记录持久化 + 重建”的联动；重启后对话历史丢失。
2) 现有 RAG 质量不稳定：发送时先把当前输入保存为记忆，再检索，容易命中“刚输入的句子”形成回显；同时 context 以拼字符串方式混在 user content 中，不利于模型区分。

## 2. 现状（基于当前代码的事实）
### 2.1 对话主链路
- 发送入口：ChatScreen -> ChatViewModel.sendMessage
- 发送时会把 user 文本写入记忆库：ChatViewModel.sendMessage 内调用 ragService.saveMemory(text, "user")
- RAG：ragService.prepareContext(text) 会 embed(userQuery) 并做向量近邻检索 top5
- Prompt：ChatViewModel.buildPrompt(systemPrompt + context + User:...) 拼成一个字符串
- LLM：LLMService.chat 以 messages=[{role:"user", content: fullPrompt}] 发送
- 完成后会把 assistant 原始响应写入记忆库：ragService.saveMemory(finalResponse, "ai")

### 2.2 本地记忆库
- DB：ObjectBox（Hilt 提供 BoxStore）
- MemoryEntity：包含 text/embedding/timestamp/emotion(当前被当作 user/ai 标签使用)
- 检索：ObjectBox nearestNeighbors(queryEmbedding, limit)

### 2.3 旁路实现
- 存在 Room 版 MemoryEntity/LLMRepository（可将 history 转 messages），但主链路未使用，存在维护分叉风险。

## 3. 目标（完美状态验收标准）
### 3.1 功能目标
- G1：每次对话同时利用：
  - 短期上下文：最近 N 轮会话消息（结构化 messages）
  - 长期记忆：本地向量检索出的相关记忆（RAG context）
- G2：会话持久化：
  - 重启后可恢复最近 session 与消息列表
- G3：RAG 质量：
  - 默认不会把“刚输入的句子”作为记忆召回
  - 具备去重、阈值过滤、时间衰减、按类型过滤
- G4：数据层收敛：
  - 对话/记忆只走一套权威实现（ObjectBox 优先），旁路 Room 实现要么移除要么迁移复用
- G5：记忆花园闭环：
  - MemoryGarden 可新增/编辑/删除“手动记忆（manual）”，且能被对话召回

### 3.2 非目标（本轮不做/可后续）
- 真正的服务端流式 SSE（当前仍可维持“模拟流式”）
- 多端同步、云端备份、账户体系

## 4. 总体方案概览
- 统一本地存储：继续使用 ObjectBox
- 新增会话与消息实体：ChatSessionEntity、ChatMessageEntity
- 记忆实体增强：MemoryEntity 增加 tag/source/sessionId 等元信息（尽量以“新增字段”方式做兼容迁移，避免字段重命名破坏）
- 结构化 messages 发送：system / memory_context / history / user 分层
- RAG 升级：候选 topK + 本地相似度计算 + 过滤/排序

## 5. 数据模型设计（ObjectBox）
### 5.1 ChatSessionEntity（新）
字段建议：
- id: Long（ObjectBox @Id）
- title: String?（可选；默认可由首条 user 内容截断生成）
- createdAt: Long
- updatedAt: Long
- isArchived: Boolean（可选）

### 5.2 ChatMessageEntity（新）
字段建议：
- id: Long
- sessionId: Long（索引；用于按会话查消息）
- role: String（"user" | "assistant" | "system"；实际主要是 user/assistant）
- content: String（存“干净文本”，不包含 emotion/gesture tag）
- rawContent: String?（可选；存模型原始输出，含标签，方便复盘/重新解析）
- timestamp: Long（索引；用于排序）

### 5.3 MemoryEntity（现有增强）
现有字段：text, embedding, timestamp, emotion(当前被当作标签用)
增强策略（避免重命名导致迁移风险）：
- 新增字段：
  - tag: String（"user_input" | "ai_output" | "manual" | "summary"）
  - sessionId: Long（可选；如果来自某次会话，可关联）
  - emotionLabel: String?（如果你需要真实情绪字段，优先新增 emotionLabel，而不要复用旧 emotion）
- 兼容策略：
  - 读取时：如果 tag 为空，则把旧 emotion 当作 tag 兼容解析（user/ai -> user_input/ai_output）
  - 写入时：统一写入 tag；emotionLabel 只写真实情绪

## 6. Repository 与 Service API 设计
### 6.1 ChatRepository（新）
核心接口：
- getOrCreateActiveSession(): Long
- observeMessages(sessionId: Long, limit: Int): Flow<List<ChatMessageEntity>>
- getRecentMessages(sessionId: Long, limit: Int): List<ChatMessageEntity>
- appendMessage(sessionId: Long, role: String, content: String, rawContent: String? = null): Long
- updateSessionTimestamp(sessionId: Long)

### 6.2 MemoryRepository（增强）
在现有 save/search 的基础上，增加可选参数：
- save(text: String, tag: String, sessionId: Long? = null, emotionLabel: String? = null)
- search(queryEmbedding: FloatArray, limit: Int, allowedTags: Set<String> = ...): List<MemoryEntity>
- （可选）getRecentMemories(limit)

### 6.3 RAGService（增强）
新增配置参数（可注入默认值）：
- topKCandidates = 20
- maxContextItems = 5
- minSimilarity = 0.25~0.35（可调）
- halfLifeDays = 14（时间衰减半衰期）
- allowedTagsForChat = {manual, summary, user_input}（默认不取 ai_output，避免自循环）

算法（确定性流程）：
1) queryEmbedding = embed(userInput)
2) candidates = memoryRepository.search(queryEmbedding, limit=topKCandidates, allowedTags)
3) 对每条 candidate 计算 cosineSimilarity(queryEmbedding, candidate.embedding)
4) 过滤：
   - similarity < minSimilarity -> 丢弃
   - 与当前输入完全相同且时间差 < 3s -> 丢弃（作为保险）
5) 去重：按 text 去重，只保留 timestamp 最新的一条
6) 排序：score = similarity * exp(-ageDays / halfLifeDays)
7) 取 top maxContextItems
8) 格式化为 context 文本（建议带时间、tag）：
   - "Relevant Memories (for reference):\n- [yyyy-MM-dd HH:mm][tag] text"

## 7. ViewModel 发送流程（新主链路）
以 ChatViewModel.sendMessage 为核心，目标是“结构化 + 可恢复”。

### 7.1 发送流程（按顺序）
1) sessionId = chatRepository.getOrCreateActiveSession()
2) UI state 立即追加 userMessage（同时落库）：
   - chatRepository.appendMessage(sessionId, role="user", content=text)
3) RAG（注意顺序：先检索再保存本次输入为长期记忆，避免自匹配）：
   - context = ragService.prepareContext(text, sessionId)
4) history = chatRepository.getRecentMessages(sessionId, limit = N)
   - history 不需要包含刚刚那条 user（也可以包含，二选一；我建议包含，以保证一致）
5) messages = buildMessages(systemPrompt, context, history, currentUserInput)
6) 调用 LLM：llmService.chatStream(messages)
7) 收到完整输出：
   - parse emotion/gesture（现有逻辑保留）
   - assistantCleanText = parsed.text
   - chatRepository.appendMessage(sessionId, role="assistant", content=assistantCleanText, rawContent=finalResponse)
8) 长期记忆写入：
   - 保存 user_input（tag=user_input, sessionId=sessionId）
   - 保存 ai_output（tag=ai_output, sessionId=sessionId, emotionLabel=parsed.emotion）
9) 更新 UI state（同时保证与 observeMessages 能一致）

### 7.2 messages 构建规则
messages 顺序：
1) system: persona/systemPrompt
2) system: memory context（若为空则跳过）
3) history: 最近 N 条 user/assistant（按 timestamp）
4) user: 当前输入

注意：不要再把 system/context 混到 user content 里，避免模型把“记忆”当成用户输入。

## 8. MemoryGarden（闭环）
### 8.1 FAB 新增记忆
- 点击 FAB -> 弹窗输入 -> 调用 MemoryGardenViewModel.addMemory(text, tag="manual")
- 写入后自动触发 ObjectBox reactive 更新，星图立即刷新

### 8.2 记忆详情
- 详情卡展示：text、时间、tag、（可选）sessionId
- 支持编辑/删除：更新 embedding、更新 tag/emotionLabel

## 9. 旁路 Room 实现的处理策略（必须收敛）
给出两条收敛策略，落地时二选一：
- 策略 1（推荐）：删除/下线未使用的 Room MemoryEntity/LLMRepository，主流程统一 ObjectBox。
- 策略 2（若项目已大量依赖 Room）：将 Room 仅用于 ChatSession/ChatMessage，ObjectBox 仅用于向量记忆；但需要双库维护与 DI 分层，复杂度更高。

一次到位目标下，我默认采用“策略 1”。

## 10. 迁移与兼容性说明
- ObjectBox 新增 Entity/字段一般可自动兼容（新增字段不会破坏已有数据）。
- 避免直接重命名 MemoryEntity 旧字段（例如 emotion），采用“新增 tag/emotionLabel + 读取兼容”方案。
- 首次启动时：
  - 若发现 tag 为空且 emotion 为 "user"/"ai"，则在读取层映射到 tag（不强制回写；如需可做一次性后台修复任务）。

## 11. 配置与可调参数（默认值建议）
- historyLimit: 12~20 条消息（按字符上限二次截断）
- ragTopKCandidates: 20
- ragMaxItems: 5
- ragMinSimilarity: 0.30
- ragHalfLifeDays: 14
- ragAllowedTags: {manual, summary, user_input}

（这些做成常量或通过 UserPreferencesRepository 可配置开关，便于后续调参。）

## 12. 验收测试清单（实现阶段必须逐条过）
- T1：发送消息正常返回；UI typing（模拟流式）正常
- T2：RAG context 不包含“刚输入的句子”回显（重复输入也不应无限回显）
- T3：重启 App 后 ChatScreen 能恢复最近会话消息列表
- T4：MemoryGarden 新增 manual 记忆后，下一次对话能召回该记忆（context 中出现）
- T5：ai_output 默认不参与 RAG（避免自循环），除非显式打开开关
- T6：编译通过 + 基础单测（至少覆盖 cosineSimilarity/过滤/去重/排序）

## 13. 具体改动清单（文件级别，便于新对话实现时直接照着做）
新增（建议路径）：
- core/data/chat/ChatSessionEntity.kt
- core/data/chat/ChatMessageEntity.kt
- core/data/chat/ChatRepository.kt
- core/data/chat/ObjectBoxChatRepository.kt

修改：
- ui/viewmodel/ChatViewModel.kt（发送流程重排、结构化 messages、落库与恢复）
- core/data/brain/LLMService.kt（新增 chat(messages) 与 chatStream(messages) 重载）
- data/model/llm/ChatRequest.kt（如已支持 messages 则无需改；只保证可传多条）
- core/data/brain/RAGService.kt（支持过滤/排序/allowedTags/sessionId）
- core/data/memory/MemoryEntity.kt（新增 tag/sessionId/emotionLabel 字段）
- core/data/memory/MemoryRepository.kt / ObjectBoxMemoryRepository.kt（save/search 参数增强）
- ui/screens/MemoryGardenScreen.kt（FAB 接入新增记忆）
- ui/viewmodel/MemoryGardenViewModel.kt（addMemory 传 tag=manual，并保证写入 embedding）
- di/AppModule.kt（绑定 ChatRepository）

删除/收敛（按策略 1）：
- data/memory/MemoryEntity.kt（Room 版）
- data/repository/LLMRepository.kt（若确认为旁路未使用）
（删除前会全局检索引用，确保不影响其他功能。）

---

这份文档就是你开新对话时的“实施说明书”。你确认后，我在新对话会按第 13 节的文件清单直接落地，并逐条跑第 12 节验收。